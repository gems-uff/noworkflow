{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Summer of Reproducibility - noWorkflow Base Experiment - Notebook 1\n",
    "This Jupyter Notebook is dedicated to guiding you through the applications of noWorkflow in Data Science and Machine Learning. It is the outcome of our participation in the Summer of Reproducibility at OSPO UCSC 2023, utilizing [noWorkflow](https://github.com/gems-uff/noworkflow).\n",
    "\n",
    "This Notebook serves as a use case based on the problem of Fraud Detection. We have partially replicated the work entitled \"The Effect of Feature Extraction and Data Sampling on Credit Card Fraud Detection.\" Interested readers are encouraged to refer to the original paper [here](https://link.springer.com/article/10.1186/s40537-023-00684-w).\n",
    "\n",
    "For the sake of clarity, we have divided this experiment into different notebooks:\n",
    "\n",
    "1. Covers the steps from reading the dataset to a Random Forest model training, configuring a single trial.\n",
    "2. Repeats all previous steps but with changes in the experimental setup, such as modified hyperparameters.\n",
    "3. Utilizes noWorkflow to summarize the results from previous trials.\n",
    "4. Repeat the experiment, changing the model and the order of operations.\n",
    "5. Compares the modifications and differences between the last and first experiments.\n",
    "\n",
    "**Please, remember to select the noWorkflow kernel before running these Notebooks.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "\n",
    "from noworkflow.now.tagging.var_tagging import backward_deps, \\\n",
    "    global_backward_deps, store_operations, resume_trials, trial_diff, \\\n",
    "    trial_intersection_diff, var_tag_plot, var_tag_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset/creditcard.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering stage\n",
    "\n",
    "Separate the features and target variables. It is the first step in feature treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Class', axis=1)\n",
    "y = df['Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature engineering: Applying PCA for feature extraction.\n",
    "\n",
    "Here, a pca_components tag is created to retain the n_components argument used in the PCA operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation(id=155, checkpoint=3859.822927932, code_component_id=1099, activation_id=152, repr=3)\n"
     ]
    }
   ],
   "source": [
    "pca_components = now_variable('pca_components', 3)\n",
    "pca = PCA(n_components=pca_components)\n",
    "X_pca = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature engineering: Applying random undersampling over the extracted features\n",
    "\n",
    "Another case of feature engineering operation with hyperparameter definition. Here is *random_state* value for RandomUnderSampler function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation(id=51, checkpoint=32.867074206, code_component_id=903, activation_id=48, repr=42)\n"
     ]
    }
   ],
   "source": [
    "random_seed = now_variable('random_seed', 42)\n",
    "rus = RandomUnderSampler(random_state=random_seed)\n",
    "X_resampled, y_resampled = rus.fit_resample(X_pca, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Feature engineering: Spliting dataset into train and test\n",
    "\n",
    "Here we have two hyperparameters assignments: the proportion of the test_size and the random_state. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation(id=70, checkpoint=33.053857322, code_component_id=939, activation_id=67, repr=0.2)\n"
     ]
    }
   ],
   "source": [
    "test_dim = now_variable('test_dim', 0.2)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=test_dim, random_state=random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scoring: model training and transforming features into predictions\n",
    "##### RandomForest\n",
    "\n",
    "Instantiate and evaluate a Random Forest Classifier. Here we are tagging the model name in a model object "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation(id=89, checkpoint=33.209249015, code_component_id=973, activation_id=85, repr=RandomForestClassifier())\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = now_variable('model', RandomForestClassifier())\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Evaluating: evaluating the performance of models\n",
    "##### RandomForest\n",
    "\n",
    "Computing performance metrics. Two control variables are tagged here. *roc_metric* stores the ROC score classical metric in classification. On the other hand, *f1_metric* is the F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation(id=111, checkpoint=33.548601773, code_component_id=1010, activation_id=100, repr=0.817305710162853)\n",
      "Evaluation(id=120, checkpoint=33.550994317, code_component_id=1026, activation_id=100, repr=0.8181818181818183)\n",
      "Random Forest - ROC = 0.817306, F1 = 0.818182\n"
     ]
    }
   ],
   "source": [
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "roc_metric = now_variable('roc_metric', roc_auc_score(y_test, y_pred))\n",
    "f1_metric = now_variable('f1_metric', f1_score(y_test, y_pred))\n",
    "\n",
    "print(\"Random Forest - ROC = %f, F1 = %f\" % (roc_metric, f1_metric))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Experiment dependencies from roc_metric variable\n",
    "\n",
    "When calling the backward_deps('tagged_var_name'), \n",
    "we receive a list of variables that are involved in the computation of the tagged variable. In this example, if you call it with the 'roc_metric' tag, the output will include all operations that were involved in the construction of its final value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{26: ('y_test', 'complex data type'),\n",
       " 25: ('RandomForestClassifier()', 'complex data type'),\n",
       " 24: (\"now_variable('model', RandomForestClassifier())\", 'complex data type'),\n",
       " 23: ('rf', 'complex data type'),\n",
       " 22: ('X_resampled', 'complex data type'),\n",
       " 21: ('RandomUnderSampler(random_state=random_seed)', 'complex data type'),\n",
       " 20: ('rus', 'complex data type'),\n",
       " 19: (\"now_variable('pca_components', 3)\", '3'),\n",
       " 18: ('pca_components', '3'),\n",
       " 17: ('PCA(n_components=pca_components)', 'PCA(n_components=3)'),\n",
       " 16: ('pca', 'PCA(n_components=3)'),\n",
       " 15: ('X', 'complex data type'),\n",
       " 14: ('X_pca', 'complex data type'),\n",
       " 13: ('df', 'complex data type'),\n",
       " 12: (\"df['Class']\", 'complex data type'),\n",
       " 11: ('y', 'complex data type'),\n",
       " 10: ('y_resampled', 'complex data type'),\n",
       " 9: (\"now_variable('test_dim', 0.2)\", '0.2'),\n",
       " 8: ('test_dim', '0.2'),\n",
       " 7: (\"now_variable('random_seed', 42)\", '42'),\n",
       " 6: ('random_seed', '42'),\n",
       " 5: ('train_test_split(X_resampled, y_resampled, test_size=test_dim, random_state=random_seed)',\n",
       "  'complex data type'),\n",
       " 4: ('X_test', 'complex data type'),\n",
       " 3: ('y_pred', 'complex data type'),\n",
       " 2: ('roc_auc_score(y_test, y_pred)', '0.817305710162853'),\n",
       " 1: (\"now_variable('roc_metric', roc_auc_score(y_test, y_pred))\",\n",
       "  '0.817305710162853'),\n",
       " 0: ('roc_metric', '0.817305710162853')}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_ops = backward_deps('roc_metric', False)\n",
    "dict_ops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Experiment dependencies from roc_metric\n",
    "\n",
    "Save the operations dictionary in a shelve object with this trial_id as a key.\n",
    "\n",
    "Steps are:\n",
    "1. calls store operations() to store the dict into a shelve object with this trial_id key\n",
    "2. verify the list of stored trials available to comparision with resume_trials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary stored in shelve.\n"
     ]
    }
   ],
   "source": [
    "trial_id = __noworkflow__.trial_id\n",
    "store_operations(trial_id, dict_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['edb94455-f97b-46f0-b30e-ed01eaf81081']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resume_trials()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Next steps\n",
    "\n",
    "The [next notebook](now_usecase_part_2.ipynb) performs a similar (but not identical) trial, which we will compare in the future."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "noworkflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Apr  5 2022, 01:53:17) \n[Clang 12.0.0 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "fd46906d0be51105938edee03e9704979453c4958d5b4d09c310e6ecda521c36"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
