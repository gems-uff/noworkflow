{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Summer of Reproducibility - noWorkflow Base Experiment - Notebook 2\n",
    "This Jupyter Notebook is dedicated to guiding you through the applications of noWorkflow in Data Science and Machine Learning. It is the outcome of our participation in the Summer of Reproducibility at OSPO UCSC 2023, utilizing [noWorkflow](https://github.com/gems-uff/noworkflow).\n",
    "\n",
    "This Notebook serves as a use case based on the problem of Fraud Detection. We have partially replicated the work entitled \"The Effect of Feature Extraction and Data Sampling on Credit Card Fraud Detection.\" Interested readers are encouraged to refer to the original paper [here](https://link.springer.com/article/10.1186/s40537-023-00684-w).\n",
    "\n",
    "For the sake of clarity, we have divided this experiment into different notebooks:\n",
    "\n",
    "1. Covers the steps from reading the dataset to a Random Forest model training, configuring a single trial.\n",
    "2. Repeats all previous steps but with changes in the experimental setup, such as modified hyperparameters.\n",
    "3. Utilizes noWorkflow to summarize the results from previous trials.\n",
    "4. Repeat the experiment, changing the model and the order of operations.\n",
    "5. Compares the modifications and differences between the last and first experiments.\n",
    "\n",
    "**Please, remember to select the noWorkflow kernel before running these Notebooks.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost as cat\n",
    "\n",
    "from noworkflow.now.tagging.var_tagging import backward_deps, \\\n",
    "    global_backward_deps, store_operations, resume_trials, trial_diff, \\\n",
    "    trial_intersection_diff, var_tag_plot, var_tag_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset/creditcard.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering stage\n",
    "\n",
    "Separate the features and target variable. First step in feature treatment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Class', axis=1)\n",
    "y = df['Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature engineering: Apply PCA for feature extraction.\n",
    "\n",
    "Here we define *pca_components* tag to keep the n_components argument in PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation(id=33, checkpoint=28.039946395, code_component_id=870, activation_id=30, repr=5)\n"
     ]
    }
   ],
   "source": [
    "pca_components = now_variable('pca_components', 5)\n",
    "pca = PCA(n_components=pca_components)  # Adjust the number of components as needed\n",
    "X_pca = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature engineering: Apply random undersampling over the extracted features\n",
    "\n",
    "Another case of feature engineering operation with hyperparameter definition. Here is *random_state* value for RandomUnderSampler function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation(id=51, checkpoint=28.973825146, code_component_id=903, activation_id=48, repr=123456)\n"
     ]
    }
   ],
   "source": [
    "random_seed = now_variable('random_seed', 123456)\n",
    "rus = RandomUnderSampler(random_state=random_seed)\n",
    "X_resampled, y_resampled = rus.fit_resample(X_pca, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Feature engineering: Spliting dataset into train and test\n",
    "\n",
    "Here we have two hyperparameters assignments: the proportion of the test_size and the random_state. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation(id=70, checkpoint=29.140405569, code_component_id=939, activation_id=67, repr=0.3)\n"
     ]
    }
   ],
   "source": [
    "test_dim = now_variable('test_dim', 0.3)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=test_dim, random_state=random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scoring: model training and transforming features into predictions\n",
    "##### RandomForest\n",
    "\n",
    "Instantiate and evaluate a Random Forest Classifier. Here we are tagging the model name in a model object "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation(id=89, checkpoint=29.242390443, code_component_id=973, activation_id=85, repr=RandomForestClassifier())\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = now_variable('model', RandomForestClassifier())\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Evaluating: evaluating the performance of models\n",
    "##### RandomForest\n",
    "\n",
    "Computing performance metrics. Two control variables are tagged here. *roc_rf* stores the ROC score classical metric in classification. On the other hand, *f1_rf* is the F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation(id=111, checkpoint=29.49682554, code_component_id=1010, activation_id=100, repr=0.9254794520547944)\n",
      "Evaluation(id=120, checkpoint=29.499553267, code_component_id=1026, activation_id=100, repr=0.9236111111111112)\n",
      "Random Forest - ROC = 0.925479, F1 = 0.923611\n"
     ]
    }
   ],
   "source": [
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "roc_metric = now_variable('roc_metric', roc_auc_score(y_test, y_pred))\n",
    "f1_metric = now_variable('f1_metric', f1_score(y_test, y_pred))\n",
    "\n",
    "print(\"Random Forest - ROC = %f, F1 = %f\" % (roc_metric, f1_metric))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Experiment dependencies from roc_metric variable\n",
    "\n",
    "When calling the backward_deps('tagged_var_name'), \n",
    "we receive a list of variables that are involved in the computation of the tagged variable. In this example, if you call it with the 'roc_metric' tag, the output will include all operations that were involved in the construction of its final value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{26: ('y_test', 'complex data type'),\n",
       " 25: ('RandomForestClassifier()', 'complex data type'),\n",
       " 24: (\"now_variable('model', RandomForestClassifier())\", 'complex data type'),\n",
       " 23: ('rf', 'complex data type'),\n",
       " 22: ('X_resampled', 'complex data type'),\n",
       " 21: ('RandomUnderSampler(random_state=random_seed)', 'complex data type'),\n",
       " 20: ('rus', 'complex data type'),\n",
       " 19: (\"now_variable('pca_components', 5)\", '5'),\n",
       " 18: ('pca_components', '5'),\n",
       " 17: ('PCA(n_components=pca_components)', 'PCA(n_components=5)'),\n",
       " 16: ('pca', 'PCA(n_components=5)'),\n",
       " 15: ('X', 'complex data type'),\n",
       " 14: ('X_pca', 'complex data type'),\n",
       " 13: ('df', 'complex data type'),\n",
       " 12: (\"df['Class']\", 'complex data type'),\n",
       " 11: ('y', 'complex data type'),\n",
       " 10: ('y_resampled', 'complex data type'),\n",
       " 9: (\"now_variable('test_dim', 0.3)\", '0.3'),\n",
       " 8: ('test_dim', '0.3'),\n",
       " 7: (\"now_variable('random_seed', 123456)\", '123456'),\n",
       " 6: ('random_seed', '123456'),\n",
       " 5: ('train_test_split(X_resampled, y_resampled, test_size=test_dim, random_state=random_seed)',\n",
       "  'complex data type'),\n",
       " 4: ('X_test', 'complex data type'),\n",
       " 3: ('y_pred', 'complex data type'),\n",
       " 2: ('roc_auc_score(y_test, y_pred)', '0.9254794520547944'),\n",
       " 1: (\"now_variable('roc_metric', roc_auc_score(y_test, y_pred))\",\n",
       "  '0.9254794520547944'),\n",
       " 0: ('roc_metric', '0.9254794520547944')}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_ops = backward_deps('roc_metric', False)\n",
    "dict_ops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Experiment dependencies from roc_metric\n",
    "Save the operations dictionary in a shelve object with this trial_id as a key.\n",
    "\n",
    "Steps are:\n",
    "1. calls store operations() to store the dict into a shelve object with this trial_id key.\n",
    "2. Verify the list of stored trials available for comparison with resume_trials()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary stored in shelve.\n"
     ]
    }
   ],
   "source": [
    "trial_id = __noworkflow__.trial_id\n",
    "store_operations(trial_id, dict_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['edb94455-f97b-46f0-b30e-ed01eaf81081',\n",
       " 'b86773c3-a3b7-40d0-a3ac-5ab4278826c2']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resume_trials()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Next steps\n",
    "\n",
    "In the next [Notebook](./now_usecase_part_3.ipynb) in this series, we will focus on comparing these two experiments with the noWorkflow "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "noWorkflow 3",
   "language": "python",
   "name": "noworkflow3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "fd46906d0be51105938edee03e9704979453c4958d5b4d09c310e6ecda521c36"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
